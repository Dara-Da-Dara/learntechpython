{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tywhkF2aWLGd"
      },
      "source": [
        " LangGraph\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Q6MRFU0fGKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project Title\n",
        "\n",
        "Intelligent Customer Support Ticket Automation using LangGraph and Hugging Face\n",
        "\n",
        "1. Business Problem\n",
        "\n",
        "Modern organizations receive a very large number of customer support tickets through:\n",
        "\n",
        "Emails\n",
        "\n",
        "Chatbots\n",
        "\n",
        "Web forms\n",
        "\n",
        "Social media\n",
        "\n",
        "These tickets vary in:\n",
        "\n",
        "Topic (billing, technical issue, account access, etc.)\n",
        "\n",
        "Urgency (normal vs critical)\n",
        "\n",
        "Complexity\n",
        "\n",
        "Current Challenges\n",
        "\n",
        "Manual ticket triage is slow and costly\n",
        "\n",
        "Support agents waste time reading long messages\n",
        "\n",
        "High-priority tickets may be missed\n",
        "\n",
        "Response quality varies between agents\n",
        "\n",
        "2. Project Objective\n",
        "\n",
        "The goal of this project is to automate the initial handling of customer support tickets using AI, so that:\n",
        "\n",
        "Tickets are automatically understood\n",
        "\n",
        "Important issues are prioritized\n",
        "\n",
        "Support agents receive summaries and suggested replies\n",
        "\n",
        "Overall response time and cost are reduced\n",
        "\n",
        "The system must:\n",
        "\n",
        "Work without paid APIs\n",
        "\n",
        "Be scalable and modular\n",
        "\n",
        "Use open-source models\n",
        "\n",
        "3. Why LangGraph + Hugging Face?\n",
        "Hugging Face\n",
        "\n",
        "Provides pre-trained and fine-tunable NLP models\n",
        "\n",
        "Supports tasks like classification, summarization, and text generation\n",
        "\n",
        "Can run locally, avoiding external APIs\n",
        "\n",
        "LangGraph\n",
        "\n",
        "Orchestrates AI workflows as a graph\n",
        "\n",
        "Maintains state across multiple steps\n",
        "\n",
        "Supports branching, decision-making, and memory\n",
        "\n",
        "Ideal for multi-step business logic (not just single prompts)\n",
        "\n",
        "Together, they create a production-ready AI pipeline.\n",
        "\n",
        "4. High-Level System Architecture\n",
        "\n",
        "The system is designed as a multi-stage AI workflow, not a single model call.\n",
        "\n",
        "Input\n",
        "\n",
        "A raw customer ticket (text)\n",
        "\n",
        "Processing Pipeline\n",
        "\n",
        "Each step is handled by a dedicated AI model and coordinated by LangGraph.\n",
        "\n",
        "Output\n",
        "\n",
        "Ticket category\n",
        "\n",
        "Urgency level\n",
        "\n",
        "Short summary\n",
        "\n",
        "Suggested response\n",
        "\n",
        "5. Workflow Explanation (Step-by-Step)\n",
        "Step 1: Ticket Ingestion\n",
        "\n",
        "The system receives a customer message\n",
        "\n",
        "This could come from email, chat, or a helpdesk system\n",
        "\n",
        "The raw text is stored in the workflow state\n",
        "\n",
        "Step 2: Ticket Classification\n",
        "\n",
        "A text classification model analyzes the ticket\n",
        "\n",
        "It determines the ticket type (e.g., Billing, Technical, General)\n",
        "\n",
        "This information helps route the ticket to the correct team\n",
        "\n",
        "Business value:\n",
        "Reduces manual sorting and misrouting\n",
        "\n",
        "Step 3: Urgency Detection\n",
        "\n",
        "Another model checks if the ticket is urgent\n",
        "\n",
        "Keywords and context are analyzed (e.g., “service down”, “payment failed”)\n",
        "\n",
        "Urgent tickets are flagged for priority handling\n",
        "\n",
        "Business value:\n",
        "Critical issues are addressed faster\n",
        "\n",
        "Step 4: Ticket Summarization\n",
        "\n",
        "Long customer messages are condensed into 2–3 lines\n",
        "\n",
        "The summary highlights the core problem\n",
        "\n",
        "Agents no longer need to read the full message\n",
        "\n",
        "Business value:\n",
        "Improves agent efficiency and reduces cognitive load\n",
        "\n",
        "Step 5: Suggested Response Generation\n",
        "\n",
        "A language generation model creates a draft reply\n",
        "\n",
        "The response is polite, contextual, and relevant\n",
        "\n",
        "Agents can edit or approve it before sending\n",
        "\n",
        "Business value:\n",
        "Speeds up responses while maintaining quality\n",
        "\n",
        "Step 6: Final Output\n",
        "\n",
        "The system produces a structured result:\n",
        "\n",
        "Category\n",
        "\n",
        "Urgency flag\n",
        "\n",
        "Summary\n",
        "\n",
        "Suggested reply\n",
        "\n",
        "This output is sent to:\n",
        "\n",
        "A support dashboard\n",
        "\n",
        "A CRM system\n",
        "\n",
        "Or directly to a human agent\n",
        "\n",
        "6. Role of LangGraph in the Project\n",
        "\n",
        "LangGraph:\n",
        "\n",
        "Connects all steps as nodes in a graph\n",
        "\n",
        "Passes information (state) between nodes\n",
        "\n",
        "Ensures the workflow runs in the correct order\n",
        "\n",
        "Allows future branching (e.g., auto-escalation if urgent)\n",
        "\n",
        "Without LangGraph, this would be hard-coded logic.\n",
        "With LangGraph, it becomes flexible, readable, and scalable.\n",
        "\n",
        "7. Model Usage Strategy\n",
        "\n",
        "Each task uses the most suitable model, instead of one large model doing everything.\n",
        "\n",
        "Classification model → understanding intent\n",
        "\n",
        "Summarization model → condensing information\n",
        "\n",
        "Generation model → drafting responses\n",
        "\n",
        "This improves:\n",
        "\n",
        "Accuracy\n",
        "\n",
        "Speed\n",
        "\n",
        "Resource efficiency\n",
        "\n",
        "8. Scalability and Extensibility\n",
        "\n",
        "This project can be easily extended to:\n",
        "\n",
        "Multilingual support\n",
        "\n",
        "Automatic escalation to managers\n",
        "\n",
        "Sentiment analysis\n",
        "\n",
        "Feedback-based re-training\n",
        "\n",
        "Analytics dashboards for ticket trends\n",
        "\n",
        "9. Business Impact\n",
        "Operational Benefits\n",
        "\n",
        "Faster ticket handling\n",
        "\n",
        "Reduced manual effort\n",
        "\n",
        "Lower support costs\n",
        "\n",
        "Customer Benefits\n",
        "\n",
        "Faster responses\n",
        "\n",
        "More consistent communication\n",
        "\n",
        "Better issue resolution\n",
        "\n",
        "Technical Benefits\n",
        "\n",
        "No vendor lock-in\n",
        "\n",
        "Fully open-source\n",
        "\n",
        "Works offline or on-premise\n",
        "\n",
        "10. Summary\n",
        "\n",
        "This project demonstrates how LangGraph and Hugging Face can be combined to build a real-world AI system that goes beyond simple chatbots.\n",
        "\n",
        "It shows:\n",
        "\n",
        "Practical AI orchestration\n",
        "\n",
        "Responsible use of open-source models\n",
        "\n",
        "Clear business value\n",
        "\n",
        "In short, it is a production-ready AI workflow for intelligent customer support automation."
      ],
      "metadata": {
        "id": "Doi-SzXlfGkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/sample_data/requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5ChBn-wXVz2",
        "outputId": "066aa995-38d4-4edc-c5ec-dfcbbf195303"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/sample_data/requirements.txt (line 2)) (1.2.7)\n",
            "Requirement already satisfied: langgraph>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/sample_data/requirements.txt (line 4)) (1.0.7)\n",
            "Requirement already satisfied: transformers>=4.40.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/sample_data/requirements.txt (line 7)) (4.57.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from -r /content/sample_data/requirements.txt (line 8)) (0.36.0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/sample_data/requirements.txt (line 11)) (2.9.0+cpu)\n",
            "Requirement already satisfied: accelerate>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/sample_data/requirements.txt (line 13)) (1.12.0)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/sample_data/requirements.txt (line 16)) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/sample_data/requirements.txt (line 19)) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/sample_data/requirements.txt (line 20)) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/sample_data/requirements.txt (line 23)) (4.67.1)\n",
            "Requirement already satisfied: tokenizers>=0.14.3 in /usr/local/lib/python3.12/dist-packages (from -r /content/sample_data/requirements.txt (line 26)) (0.22.2)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.7 in /usr/local/lib/python3.12/dist-packages (from langchain>=0.1.0->-r /content/sample_data/requirements.txt (line 2)) (1.2.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain>=0.1.0->-r /content/sample_data/requirements.txt (line 2)) (2.12.3)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph>=0.1.0->-r /content/sample_data/requirements.txt (line 4)) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph>=0.1.0->-r /content/sample_data/requirements.txt (line 4)) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph>=0.1.0->-r /content/sample_data/requirements.txt (line 4)) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph>=0.1.0->-r /content/sample_data/requirements.txt (line 4)) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r /content/sample_data/requirements.txt (line 7)) (3.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r /content/sample_data/requirements.txt (line 7)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r /content/sample_data/requirements.txt (line 7)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r /content/sample_data/requirements.txt (line 7)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r /content/sample_data/requirements.txt (line 7)) (2.32.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r /content/sample_data/requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.16.4->-r /content/sample_data/requirements.txt (line 8)) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.16.4->-r /content/sample_data/requirements.txt (line 8)) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.16.4->-r /content/sample_data/requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r /content/sample_data/requirements.txt (line 11)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r /content/sample_data/requirements.txt (line 11)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r /content/sample_data/requirements.txt (line 11)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r /content/sample_data/requirements.txt (line 11)) (3.1.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.22.0->-r /content/sample_data/requirements.txt (line 13)) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->-r /content/sample_data/requirements.txt (line 16)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->-r /content/sample_data/requirements.txt (line 16)) (0.3.8)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->-r /content/sample_data/requirements.txt (line 16)) (0.70.16)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.0->-r /content/sample_data/requirements.txt (line 20)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.0->-r /content/sample_data/requirements.txt (line 20)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.0->-r /content/sample_data/requirements.txt (line 20)) (2025.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->-r /content/sample_data/requirements.txt (line 16)) (3.13.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain>=0.1.0->-r /content/sample_data/requirements.txt (line 2)) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain>=0.1.0->-r /content/sample_data/requirements.txt (line 2)) (0.6.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain>=0.1.0->-r /content/sample_data/requirements.txt (line 2)) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain>=0.1.0->-r /content/sample_data/requirements.txt (line 2)) (0.13.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph>=0.1.0->-r /content/sample_data/requirements.txt (line 4)) (1.12.1)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph>=0.1.0->-r /content/sample_data/requirements.txt (line 4)) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph>=0.1.0->-r /content/sample_data/requirements.txt (line 4)) (3.11.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.0->-r /content/sample_data/requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.0->-r /content/sample_data/requirements.txt (line 2)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.0->-r /content/sample_data/requirements.txt (line 2)) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1.0->-r /content/sample_data/requirements.txt (line 20)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0->-r /content/sample_data/requirements.txt (line 7)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0->-r /content/sample_data/requirements.txt (line 7)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0->-r /content/sample_data/requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0->-r /content/sample_data/requirements.txt (line 7)) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->-r /content/sample_data/requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->-r /content/sample_data/requirements.txt (line 11)) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->-r /content/sample_data/requirements.txt (line 16)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->-r /content/sample_data/requirements.txt (line 16)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->-r /content/sample_data/requirements.txt (line 16)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->-r /content/sample_data/requirements.txt (line 16)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->-r /content/sample_data/requirements.txt (line 16)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->-r /content/sample_data/requirements.txt (line 16)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->-r /content/sample_data/requirements.txt (line 16)) (1.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph>=0.1.0->-r /content/sample_data/requirements.txt (line 4)) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph>=0.1.0->-r /content/sample_data/requirements.txt (line 4)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph>=0.1.0->-r /content/sample_data/requirements.txt (line 4)) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.7->langchain>=0.1.0->-r /content/sample_data/requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain>=0.1.0->-r /content/sample_data/requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain>=0.1.0->-r /content/sample_data/requirements.txt (line 2)) (0.25.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-huggingface\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70YF12ZNeova",
        "outputId": "b82eb46c-e5a4-4b30-e3e2-b9e4b2dcba24"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.36.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (1.2.7)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.22.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (1.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.6.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.12.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.13.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2026.1.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.16.0)\n",
            "Downloading langchain_huggingface-1.2.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: langchain-huggingface\n",
            "Successfully installed langchain-huggingface-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Imports\n",
        "# =========================\n",
        "from typing import TypedDict, List\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Define State\n",
        "# =========================\n",
        "class TicketState(TypedDict):\n",
        "    ticket_text: str\n",
        "    category: str\n",
        "    summary: str\n",
        "    suggested_reply: str\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Load Hugging Face Models\n",
        "# =========================\n",
        "\n",
        "# 1. Classification model\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        ")\n",
        "\n",
        "# 2. Summarization model\n",
        "summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    model=\"facebook/bart-large-cnn\"\n",
        ")\n",
        "\n",
        "# 3. Text generation model\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"gpt2\"\n",
        ")\n",
        "\n",
        "\n",
        "# =========================\n",
        "# LangGraph Nodes\n",
        "# =========================\n",
        "\n",
        "def classify_ticket(state: TicketState) -> TicketState:\n",
        "    result = classifier(state[\"ticket_text\"])[0]\n",
        "    state[\"category\"] = result[\"label\"]\n",
        "    return state\n",
        "\n",
        "\n",
        "def summarize_ticket(state: TicketState) -> TicketState:\n",
        "    summary = summarizer(\n",
        "        state[\"ticket_text\"],\n",
        "        max_length=60,\n",
        "        min_length=25,\n",
        "        do_sample=False\n",
        "    )[0][\"summary_text\"]\n",
        "    state[\"summary\"] = summary\n",
        "    return state\n",
        "\n",
        "\n",
        "def suggest_response(state: TicketState) -> TicketState:\n",
        "    prompt = f\"Customer issue: {state['summary']}\\nSupport response:\"\n",
        "    response = generator(\n",
        "        prompt,\n",
        "        max_length=80,\n",
        "        num_return_sequences=1\n",
        "    )[0][\"generated_text\"]\n",
        "    state[\"suggested_reply\"] = response\n",
        "    return state\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Build LangGraph\n",
        "# =========================\n",
        "graph = StateGraph(TicketState)\n",
        "\n",
        "# Add nodes WITH NAMES\n",
        "graph.add_node(\"classify\", classify_ticket)\n",
        "graph.add_node(\"summarize\", summarize_ticket)\n",
        "graph.add_node(\"respond\", suggest_response)\n",
        "\n",
        "# Add edges USING NODE NAMES\n",
        "graph.add_edge(START, \"classify\")\n",
        "graph.add_edge(\"classify\", \"summarize\")\n",
        "graph.add_edge(\"summarize\", \"respond\")\n",
        "graph.add_edge(\"respond\", END)\n",
        "\n",
        "# Compile graph\n",
        "app = graph.compile()\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Run the Workflow\n",
        "# =========================\n",
        "input_state = {\n",
        "    \"ticket_text\": \"My internet has been down since morning and I cannot work.\"\n",
        "}\n",
        "\n",
        "output = app.invoke(input_state)\n",
        "\n",
        "print(\"\\n===== FINAL OUTPUT =====\\n\")\n",
        "print(\"Category:\", output[\"category\"])\n",
        "print(\"\\nSummary:\", output[\"summary\"])\n",
        "print(\"\\nSuggested Reply:\\n\", output[\"suggested_reply\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuS-jPqoYWUT",
        "outputId": "340710bf-dfe3-415b-a9cb-2d15f85f44b3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Your max_length is set to 60, but your input_length is only 14. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=7)\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=80) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== FINAL OUTPUT =====\n",
            "\n",
            "Category: NEGATIVE\n",
            "\n",
            "Summary: \"My internet has been down since morning and I cannot work. My internet is down,\" she said. \"I cannot work\"\n",
            "\n",
            "Suggested Reply:\n",
            " Customer issue: \"My internet has been down since morning and I cannot work. My internet is down,\" she said. \"I cannot work\"\n",
            "Support response: \"Please help us to find the source of the problem.\"\n",
            "The council confirmed it was investigating the incident and that the issue had been resolved.\n",
            "A spokesman for the city said: \"We are in contact with the CPS and are working closely with the public to try and resolve this issue.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Lehm6NBfvc4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}